{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Assignments\n",
        "\n",
        "👾 這個陽春的聊天機器人需要被優化！<br>\n",
        "若是一個對話串不間斷地持續進行，送進去的訊息量會很多，tokens數量也會跟著增加，會需要花比較多費用(💸💸💸)，也可能使模型的回應雜訊比較多而回應受到干擾，所以我們可以優化短期記憶。<br>\n",
        "另外，我們希望優化使用者體驗，我們可以根據聊天的內容整理出使用者的屬性，並在每一次跟使用者聊天時，都能根據這個使用者的狀況給予客製化的回應，因此我們要加入長期記憶的功能！\n",
        "\n",
        "<br>\n",
        "\n",
        "### 1. 短期記憶優化\n",
        "\n",
        "(1) 🔰 [基本版] 在短期記憶中，將chatbot node送入llm的訊息中加入trim的優化機制 (依據適當的tokens數量決定)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### 2. 加入長期記憶\n",
        "\n",
        "加入長期記憶，讓聊天機器人能夠記住使用者的資訊（名字、偏好語言、興趣），在下一次對話也能針對同個使用者的資訊，給予個人化的回答。\n",
        "\n",
        "(1) 🔰 [基本版]\n",
        "- chatbot node: 在chatbot node中，將該使用者的資訊取出，讓入prompt中讓llm依據使用者的資訊給予個人化的回答\n",
        "\n",
        "- write_memory node: 在每一次生成回答後，將使用者的資訊整理成一段對使用者的描述(使用llm，給予system prompt做指引，自行設計如何整理、需要整理哪些資訊)，將整理完的資訊整理到store (可跨threads存取的地方)。\n",
        "\n",
        "- config: config從原本的短期記憶只有thread_id, 也要加入user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>\n",
        "\n",
        "\n",
        "(2) 👨‍🎓 [進階版]\n",
        "- chatbot node: 可以決定使用者的問題是否需要從長期記憶中取得資訊，以及需要取得什麼資訊\n",
        "- write_memory node: 可以整理成特定格式 (例如：使用with_structured_output，相關概念可以延伸到R3 tool calling內容)。例如：\n",
        "```\n",
        "user_profile = {\n",
        "  \"first_name\": \"XXXX\",\n",
        "  \"last_name\": \"OOO\",\n",
        "  \"preferred_lang\": [\"en\", \"zh-tw\"]\n",
        "}\n",
        "```\n",
        "- 也可以自行將graph結構調整自己喜歡的(增刪不同node, conditional router, ...)\n",
        "<br>\n",
        "備註：基本版是需要大家完成的，進階版可以自行決定是否挑戰，Enjoy the ride! 😎"
      ],
      "metadata": {
        "id": "YzuZTjoZkt7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.短期記憶"
      ],
      "metadata": {
        "id": "Zprt5eyzemnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 基本版\n",
        "🔰 [基本版] 在短期記憶中，將chatbot node送入llm的訊息中加入trim的優化機制 (依據適當的tokens數量決定)\n",
        "\n",
        "note: 可以邊做邊看一下trim設定的效果以及內部運作的機制"
      ],
      "metadata": {
        "id": "PZHRs_NSsfnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -U langgraph langchain_openai==0.3.15 langchain transformers bitsandbytes langchain-huggingface langchain_core pydantic"
      ],
      "metadata": {
        "id": "m8Ahe-dgr3Qa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import trim_messages"
      ],
      "metadata": {
        "id": "zAVP32LyRqzl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 替代的 token 計算方法\n",
        "def count_tokens_approximately(messages):\n",
        "    \"\"\"簡單的 token 估算函數\"\"\"\n",
        "    total = 0\n",
        "    for message in messages:\n",
        "        if hasattr(message, 'content'):\n",
        "            # 粗略估算：英文約 4 字元 = 1 token，中文約 1 字 = 1 token\n",
        "            content = str(message.content)\n",
        "            # 簡單估算：每 3.5 個字元約等於 1 token\n",
        "            total += len(content) // 3\n",
        "    return total"
      ],
      "metadata": {
        "id": "EJcn9WmZSDlR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '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'\n",
        "os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'"
      ],
      "metadata": {
        "id": "FK2WpYUqJ7Vd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "    model=\"qwen/qwen3-14b:free\",  # 可以選擇其他模型\n",
        "    temperature=0.7,\n",
        "    max_tokens=3000\n",
        ")"
      ],
      "metadata": {
        "id": "gdDTpEgTSH1M"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "def chatbot_basic(state: State):\n",
        "    \"\"\"基本版聊天機器人，包含訊息修剪功能\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    try:\n",
        "        trimmed_messages = trim_messages(\n",
        "            messages,\n",
        "            max_tokens=2000,\n",
        "            strategy=\"last\",\n",
        "            token_counter=count_tokens_approximately,\n",
        "            include_system=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Trim messages 失敗，使用備用方案: {e}\")\n",
        "        trimmed_messages = messages[-10:]\n",
        "\n",
        "    response = llm.invoke(trimmed_messages)\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "beAp0_a0yNsP"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_basic_graph():\n",
        "    \"\"\"建立基本版 graph\"\"\"\n",
        "    graph_builder = StateGraph(State)\n",
        "    graph_builder.add_node(\"chatbot\", chatbot_basic)\n",
        "    graph_builder.add_edge(START, \"chatbot\")\n",
        "    graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "    memory = MemorySaver()\n",
        "    graph = graph_builder.compile(checkpointer=memory)\n",
        "    return graph"
      ],
      "metadata": {
        "id": "80Tj2H72VVoZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.長期記憶"
      ],
      "metadata": {
        "id": "2O2TZ8VqBpuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 基本版\n",
        "🔰 [基本版]\n",
        "- chatbot node: 在chatbot node中，將該使用者的資訊取出，讓入prompt中讓llm依據使用者的資訊給予個人化的回答\n",
        "\n",
        "- write_memory node: 在每一次生成回答後，將使用者的資訊整理成一段對使用者的描述(使用llm，給予system prompt做指引，自行設計如何整理、需要整理哪些資訊)，將整理完的資訊整理到store (可跨threads存取的地方)。\n",
        "\n",
        "- config: config從原本的短期記憶只有thread_id, 也要加入user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>"
      ],
      "metadata": {
        "id": "zZSFFrWiuE3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_with_memory(state: State, *, config):\n",
        "    \"\"\"包含長期記憶的聊天機器人\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Debug: 輸出 config 資訊\n",
        "    print(f\"=== Chatbot Config Debug ===\")\n",
        "    print(f\"Config type: {type(config)}\")\n",
        "    print(f\"Config content: {config}\")\n",
        "\n",
        "    # 從 config 取得 user_id\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    print(f\"User ID: {user_id}\")\n",
        "\n",
        "    # 嘗試獲取 store - 修正版\n",
        "    store = None\n",
        "\n",
        "    # 方法1: 直接從 config 取得\n",
        "    if hasattr(config, 'store'):\n",
        "        store = config.store\n",
        "        print(\"Store 來源: config.store\")\n",
        "    elif 'store' in config:\n",
        "        store = config['store']\n",
        "        print(\"Store 來源: config['store']\")\n",
        "\n",
        "    # 方法2: 從 configurable 中取得\n",
        "    elif 'store' in config.get('configurable', {}):\n",
        "        store = config['configurable']['store']\n",
        "        print(\"Store 來源: config['configurable']['store']\")\n",
        "\n",
        "    # 方法3: 使用全域變數\n",
        "    else:\n",
        "        global global_store\n",
        "        store = global_store\n",
        "        print(\"Store 來源: global_store\")\n",
        "\n",
        "    print(f\"Store 狀態: {store is not None}\")\n",
        "\n",
        "    # 從 store 取得使用者的長期記憶 - 修正版\n",
        "    user_memory = None\n",
        "    if store:\n",
        "        try:\n",
        "            namespace = (\"user_profiles\", user_id)\n",
        "            print(f\"嘗試讀取 namespace: {namespace}\")\n",
        "\n",
        "            # 修正：使用 get 方法而不是 search\n",
        "            memory_item = store.get(namespace, \"profile\")\n",
        "            if memory_item:\n",
        "                user_memory = memory_item.value\n",
        "                print(f\"✅ 找到使用者記憶: {user_memory[:100]}...\")\n",
        "            else:\n",
        "                print(\"❌ 沒有找到使用者記憶\")\n",
        "\n",
        "            # 額外調試：也試試 search 方法\n",
        "            try:\n",
        "                memories = list(store.search(namespace))\n",
        "                print(f\"Search 結果數量: {len(memories)}\")\n",
        "                for i, mem in enumerate(memories):\n",
        "                    print(f\"  Memory {i}: {str(mem)[:100]}...\")\n",
        "            except Exception as search_e:\n",
        "                print(f\"Search 方法錯誤: {search_e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"讀取長期記憶錯誤: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "    else:\n",
        "        print(\"⚠️  無法獲取 store\")\n",
        "\n",
        "    # 準備系統提示詞\n",
        "    system_prompt = \"你是一個友善的聊天機器人助手，請用繁體中文回應。\"\n",
        "\n",
        "    if user_memory:\n",
        "        system_prompt += f\"\\n\\n關於這個使用者的資訊：{user_memory}\\n請根據使用者的資訊給予個人化的回應。\"\n",
        "        print(\"✅ 已加入個人化資訊到系統提示中\")\n",
        "    else:\n",
        "        print(\"❌ 沒有個人化資訊可用\")\n",
        "\n",
        "    # 構建完整的訊息列表\n",
        "    full_messages = [SystemMessage(content=system_prompt)]\n",
        "\n",
        "    # 修剪歷史訊息\n",
        "    try:\n",
        "        trimmed_messages = trim_messages(\n",
        "            messages,\n",
        "            max_tokens=1500,\n",
        "            strategy=\"last\",\n",
        "            token_counter=count_tokens_approximately,\n",
        "            include_system=False\n",
        "        )\n",
        "    except Exception as e:\n",
        "        trimmed_messages = messages[-8:]\n",
        "\n",
        "    full_messages.extend(trimmed_messages)\n",
        "\n",
        "    response = llm.invoke(full_messages)\n",
        "    print(\"=== Chatbot Debug End ===\\n\")\n",
        "\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "f2PFRidLSusx"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_memory(state: State, *, config):\n",
        "    \"\"\"將對話資訊整理並寫入長期記憶\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    print(f\"=== Write Memory Debug ===\")\n",
        "    print(f\"User ID: {user_id}\")\n",
        "\n",
        "    # 嘗試獲取 store - 與讀取邏輯保持一致\n",
        "    store = None\n",
        "    if hasattr(config, 'store'):\n",
        "        store = config.store\n",
        "    elif 'store' in config:\n",
        "        store = config['store']\n",
        "    elif 'store' in config.get('configurable', {}):\n",
        "        store = config['configurable']['store']\n",
        "    else:\n",
        "        global global_store\n",
        "        store = global_store\n",
        "\n",
        "    print(f\"Store 狀態: {store is not None}\")\n",
        "\n",
        "    if not store:\n",
        "        print(\"⚠️  無法獲取 store，跳過記憶寫入\")\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        # 取得最近的對話內容\n",
        "        recent_messages = messages[-4:] if len(messages) >= 4 else messages\n",
        "\n",
        "        # 構建用於記憶整理的提示詞\n",
        "        memory_prompt = \"\"\"\n",
        "請根據以下對話內容，整理出使用者的重要資訊。\n",
        "請提取並整理：\n",
        "- 使用者的姓名或稱呼\n",
        "- 偏好的語言\n",
        "- 興趣和愛好\n",
        "- 個人特徵或背景\n",
        "- 其他重要的個人資訊\n",
        "\n",
        "請以簡潔的方式描述這個使用者，如果沒有新的重要資訊，請回答\"無新增資訊\"。\n",
        "\n",
        "對話內容：\n",
        "\"\"\"\n",
        "\n",
        "        # 添加對話內容\n",
        "        for msg in recent_messages:\n",
        "            if isinstance(msg, HumanMessage):\n",
        "                memory_prompt += f\"使用者：{msg.content}\\n\"\n",
        "            elif isinstance(msg, AIMessage):\n",
        "                memory_prompt += f\"助手：{msg.content}\\n\"\n",
        "\n",
        "        # 使用 LLM 整理記憶\n",
        "        memory_response = llm.invoke([SystemMessage(content=memory_prompt)])\n",
        "        new_memory = memory_response.content\n",
        "\n",
        "        print(f\"分析得到的新記憶: {new_memory}\")\n",
        "\n",
        "        # 如果有新的記憶資訊，則更新 store\n",
        "        if new_memory and \"無新增資訊\" not in new_memory:\n",
        "            namespace = (\"user_profiles\", user_id)\n",
        "\n",
        "            # 嘗試獲取現有記憶 - 修正版\n",
        "            existing_memory = \"\"\n",
        "            try:\n",
        "                memory_item = store.get(namespace, \"profile\")\n",
        "                if memory_item:\n",
        "                    existing_memory = memory_item.value\n",
        "                    print(f\"現有記憶: {existing_memory}\")\n",
        "            except Exception as e:\n",
        "                print(f\"讀取現有記憶錯誤: {e}\")\n",
        "\n",
        "            # 合併新舊記憶\n",
        "            if existing_memory:\n",
        "                combined_memory = f\"{existing_memory}\\n\\n新增資訊：{new_memory}\"\n",
        "            else:\n",
        "                combined_memory = new_memory\n",
        "\n",
        "            # 儲存到 store\n",
        "            store.put(namespace, \"profile\", combined_memory)\n",
        "            print(f\"✅ 已為使用者 {user_id} 儲存記憶\")\n",
        "\n",
        "            # 立即驗證寫入\n",
        "            try:\n",
        "                verify_item = store.get(namespace, \"profile\")\n",
        "                if verify_item:\n",
        "                    print(f\"✅ 驗證成功，記憶已寫入: {verify_item.value[:50]}...\")\n",
        "                else:\n",
        "                    print(\"❌ 驗證失敗，記憶可能沒有正確寫入\")\n",
        "            except Exception as verify_e:\n",
        "                print(f\"驗證錯誤: {verify_e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"記憶寫入錯誤: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"=== Write Memory Debug End ===\\n\")\n",
        "    return {}"
      ],
      "metadata": {
        "id": "BTMKnROpVlaT"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 全域 store 變數\n",
        "global_store = None"
      ],
      "metadata": {
        "id": "thbC4jt0bI_P"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_memory_graph():\n",
        "    \"\"\"建立包含長期記憶的 graph - 修正版\"\"\"\n",
        "    global global_store\n",
        "\n",
        "    builder = StateGraph(State)\n",
        "    builder.add_node(\"chatbot\", chatbot_with_memory)\n",
        "    builder.add_node(\"write_memory\", write_memory)\n",
        "    builder.add_edge(START, \"chatbot\")\n",
        "    builder.add_edge(\"chatbot\", \"write_memory\")\n",
        "    builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "    # 編譯 graph\n",
        "    memory = MemorySaver()\n",
        "    store = InMemoryStore()\n",
        "    global_store = store  # 保存全域引用\n",
        "\n",
        "    graph = builder.compile(checkpointer=memory, store=store)\n",
        "\n",
        "    print(f\"Graph 建立完成，Store: {store is not None}\")\n",
        "    print(f\"Store ID: {id(store)}\")\n",
        "    return graph, store  # 同時回傳 store"
      ],
      "metadata": {
        "id": "o2sK1m4AVpb6"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "JblBU3tecQ9-",
        "outputId": "1ba09e81-4d7b-4eb6-994f-4b71e6834ba2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7e09e7f3ac50>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 測試和使用函數"
      ],
      "metadata": {
        "id": "JFqg436etzLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(graph, user_input: str, config: dict):\n",
        "    \"\"\"串流輸出 graph 更新\"\"\"\n",
        "    try:\n",
        "        for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
        "            if \"chatbot\" in event:\n",
        "                for value in event.values():\n",
        "                    print(\"Assistant:\", value[\"messages\"][-1].content)\n",
        "    except Exception as e:\n",
        "        print(f\"串流處理錯誤: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "D4VmdBPNVsUx"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_basic_chatbot():\n",
        "    \"\"\"測試基本版聊天機器人\"\"\"\n",
        "    print(\"=== 測試基本版聊天機器人（含短期記憶優化） ===\")\n",
        "    graph = create_basic_graph()\n",
        "    config = {\"configurable\": {\"thread_id\": \"conversation_1\"}}\n",
        "\n",
        "    print(\"開始對話 (輸入 'quit', 'exit', 'q' 停止對話)\")\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"User: \")\n",
        "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "                print(\"Goodbye!\")\n",
        "                break\n",
        "            stream_graph_updates(graph, user_input, config)\n",
        "        except Exception as e:\n",
        "            print(f\"錯誤: {e}\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "o6osupNZV1Cc"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_memory_chatbot():\n",
        "    \"\"\"測試包含長期記憶的聊天機器人 - 修正版\"\"\"\n",
        "    print(\"=== 測試長期記憶聊天機器人 ===\")\n",
        "    graph, store = create_memory_graph()  # 接收 store\n",
        "\n",
        "    print(f\"Main Store ID: {id(store)}\")\n",
        "    print(f\"Global Store ID: {id(global_store)}\")\n",
        "\n",
        "    # 使用者A的第一次對話\n",
        "    print(\"\\n--- 使用者A的第一次對話 ---\")\n",
        "    # 修正：直接將 store 加入 config\n",
        "    config1 = {\n",
        "        \"configurable\": {\n",
        "            \"thread_id\": \"conversation_1\",\n",
        "            \"user_id\": \"user_a\",\n",
        "            \"store\": store  # 直接傳遞 store\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"開始對話 (輸入 'quit', 'exit', 'q' 停止對話)\")\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"User A: \")\n",
        "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "                print(\"結束第一次對話!\")\n",
        "                break\n",
        "            stream_graph_updates(graph, user_input, config1)\n",
        "        except Exception as e:\n",
        "            print(f\"錯誤: {e}\")\n",
        "            break\n",
        "\n",
        "    # 使用者A的第二次對話（新的 thread，但同一個 user）\n",
        "    print(\"\\n--- 使用者A的第二次對話 ---\")\n",
        "    # 修正：創建新的 config，但使用相同的 store\n",
        "    config2 = {\n",
        "        \"configurable\": {\n",
        "            \"thread_id\": \"conversation_2\",\n",
        "            \"user_id\": \"user_a\",\n",
        "            \"store\": store  # 使用相同的 store 實例\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(\"開始第二次對話 (輸入 'quit', 'exit', 'q' 停止對話)\")\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"User A: \")\n",
        "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "                print(\"結束第二次對話!\")\n",
        "                break\n",
        "            stream_graph_updates(graph, user_input, config2)\n",
        "        except Exception as e:\n",
        "            print(f\"錯誤: {e}\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "I0Gt0JaDV3Dz"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "進階版功能"
      ],
      "metadata": {
        "id": "EEaBC4VlV5NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UserProfile(BaseModel):\n",
        "    \"\"\"結構化的使用者檔案\"\"\"\n",
        "    first_name: Optional[str] = None\n",
        "    last_name: Optional[str] = None\n",
        "    preferred_lang: List[str] = []\n",
        "    interests: List[str] = []\n",
        "    background: Optional[str] = None\n",
        "\n",
        "def advanced_write_memory(state: State, *, config):\n",
        "    \"\"\"進階版記憶寫入，使用結構化輸出\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "\n",
        "    # 獲取 store 的邏輯與基本版保持一致\n",
        "    store = None\n",
        "    if hasattr(config, 'store'):\n",
        "        store = config.store\n",
        "    elif 'store' in config:\n",
        "        store = config['store']\n",
        "    elif 'store' in config.get('configurable', {}):\n",
        "        store = config['configurable']['store']\n",
        "    else:\n",
        "        global global_store\n",
        "        store = global_store\n",
        "\n",
        "    if not store:\n",
        "        return {}\n",
        "\n",
        "    recent_messages = messages[-4:] if len(messages) >= 4 else messages\n",
        "\n",
        "    conversation_text = \"\"\n",
        "    for msg in recent_messages:\n",
        "        if isinstance(msg, HumanMessage):\n",
        "            conversation_text += f\"使用者：{msg.content}\\n\"\n",
        "        elif isinstance(msg, AIMessage):\n",
        "            conversation_text += f\"助手：{msg.content}\\n\"\n",
        "\n",
        "    structured_llm = llm.with_structured_output(UserProfile)\n",
        "\n",
        "    try:\n",
        "        profile_prompt = f\"\"\"\n",
        "        根據以下對話，提取使用者的資訊：\n",
        "        {conversation_text}\n",
        "\n",
        "        請提取：\n",
        "        - first_name: 使用者的名字\n",
        "        - last_name: 使用者的姓氏\n",
        "        - preferred_lang: 偏好語言列表（如 [\"zh-tw\", \"en\"]）\n",
        "        - interests: 興趣愛好列表\n",
        "        - background: 背景資訊\n",
        "\n",
        "        如果某些資訊不明確，請留空。\n",
        "        \"\"\"\n",
        "\n",
        "        new_profile = structured_llm.invoke([SystemMessage(content=profile_prompt)])\n",
        "        store.put((\"user_profiles\", user_id), \"structured_profile\", new_profile.dict())\n",
        "        print(f\"已儲存結構化使用者檔案: {new_profile}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"結構化記憶寫入錯誤: {e}\")\n",
        "\n",
        "    return {}"
      ],
      "metadata": {
        "id": "mrddF3FjV5kT"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "測試"
      ],
      "metadata": {
        "id": "JcNpEgqoWDM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"聊天機器人記憶優化作業\")\n",
        "print(\"1. 測試基本版（短期記憶優化）\")\n",
        "print(\"2. 測試長期記憶版\")\n",
        "print(\"3. 退出\")\n",
        "\n",
        "while True:\n",
        "    choice = input(\"\\n請選擇測試項目 (1-3): \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        test_basic_chatbot()\n",
        "    elif choice == \"2\":\n",
        "        test_memory_chatbot()3\n",
        "    elif choice == \"3\":\n",
        "        print(\"再見！\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"無效選擇，請重試\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLp-M-u6WDAW",
        "outputId": "2539a5c8-2fa4-4705-9d97-29f671f7163d"
      },
      "execution_count": 114,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "聊天機器人記憶優化作業\n",
            "1. 測試基本版（短期記憶優化）\n",
            "2. 測試長期記憶版\n",
            "3. 退出\n",
            "\n",
            "請選擇測試項目 (1-3): 1\n",
            "=== 測試基本版聊天機器人（含短期記憶優化） ===\n",
            "開始對話 (輸入 'quit', 'exit', 'q' 停止對話)\n",
            "User: 你好\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-108-3fe4c8b9022b>\", line 4, in stream_graph_updates\n",
            "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 2436, in stream\n",
            "    for _ in runner.tick(\n",
            "  File \"<ipython-input-54-b7b75ba024bd>\", line 24, in chatbot_basic\n",
            "    response = llm.invoke(trimmed_messages)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 371, in invoke\n",
            "    \"ChatGeneration\",\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 956, in generate_prompt\n",
            "    prompt_messages = [p.to_messages() for p in prompts]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 775, in generate\n",
            "    results.append(\n",
            "        ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\", line 1021, in _generate_with_cache\n",
            "    elif inspect.signature(self._generate).parameters.get(\"run_manager\"):\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\", line 957, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\", line 925, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1239, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1034, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1748995200000'}, 'provider_name': None}}, 'user_id': 'user_2w9gBJLw3SzVow6vIHt7E17gtjY'}\n",
            "During task with name 'chatbot' and id '1c0b3bef-64d8-078d-84ef-5d0002e209b7'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "串流處理錯誤: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1748995200000'}, 'provider_name': None}}, 'user_id': 'user_2w9gBJLw3SzVow6vIHt7E17gtjY'}\n",
            "User: q\n",
            "Goodbye!\n",
            "\n",
            "請選擇測試項目 (1-3): \n",
            "無效選擇，請重試\n",
            "\n",
            "請選擇測試項目 (1-3): 3\n",
            "再見！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDlYE2obiE1G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}